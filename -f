import os
from pyspark.sql import SparkSession
import sys
from pathlib import Path

spark = SparkSession \
    .builder \
    .appName("Python Spark SQL basic example") \
    .config("spark.some.config.option", "some-value") \
    .getOrCreate()

def count_df(filename):
    path = Path(filename)
    if path.is_file():
        csv_file = spark.read.csv(filename, header=True, mode="DROPMALFORMED")
        print(csv_file.count())
        return csv_file.count()

def count_rdd(filename):
    path = Path(filename)
    if path.is_file():
        csv_file = spark.read.csv(filename, header=True, mode="DROPMALFORMED")
        print(csv_file.count())
        return csv_file.count()
